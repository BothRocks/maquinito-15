{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.4 --force"
      ],
      "metadata": {
        "id": "vBkA4W_soAFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install annoy\n",
        "!pip install cohere\n",
        "!pip install umap-learn\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "umAnS4vug6uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import umap\n",
        "\n",
        "from annoy import AnnoyIndex\n",
        "from google.colab import userdata\n",
        "from pickle import loads\n",
        "\n",
        "def get_url_content(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(file=\"ERROR: no existe el fichero {url}\")\n",
        "        print(response)\n",
        "        return None\n",
        "    return response.content\n",
        "\n",
        "def get_nearest_verses_by_vector(dataframe, search_index, v, debug=False):\n",
        "    similar_item_ids = search_index.get_nns_by_vector(v, 5, include_distances=True)\n",
        "    verses = dataframe.iloc[similar_item_ids[0]][\"text\"].tolist()\n",
        "    labels = dataframe.iloc[similar_item_ids[0]][\"label\"].tolist()\n",
        "    nearest = list(zip(verses, labels))\n",
        "    if debug:\n",
        "        print(f\"Verso: {v}\")\n",
        "        for n in nearest:\n",
        "            print(\"    \", n)\n",
        "    return nearest"
      ],
      "metadata": {
        "id": "3ZY3GBlzpWZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lee los versos originales y sus posiciones en el espacio 3D\n",
        "df = pd.read_csv(f\"https://both.rocks/maquinito-15/upniverso_data.csv\")\n",
        "\n",
        "\n",
        "# Lee los parámetros de la función que transforma 768 dimensiones en 3\n",
        "umap_content = get_url_content('https://both.rocks/maquinito-15/upniverso_umap.pkl')\n",
        "reducer = loads(umap_content)\n",
        "\n",
        "\n",
        "# Lee los índices para que las búsquedas sean más rápidas\n",
        "index_content = get_url_content('https://both.rocks/maquinito-15/upniverso_index.ann')\n",
        "with open('upniverso_index.ann', 'wb') as f:\n",
        "    f.write(index_content)\n",
        "\n",
        "search_index = AnnoyIndex(3, \"euclidean\")\n",
        "search_index.load('upniverso_index.ann')\n",
        "\n",
        "\n",
        "# Inicializa la librería de Cohere\n",
        "co = cohere.Client(userdata.get('COHERE_API_KEY'))"
      ],
      "metadata": {
        "id": "U7Fte82zpnfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verso = \"La lluvia ya no moja nuestro amor\"\n",
        "\n",
        "response = co.embed(texts=[verso], model=\"embed-multilingual-v2.0\")\n",
        "embeddings_768 = response.embeddings[0]\n",
        "embeddings_3 = reducer.transform([embeddings_768])[0]\n",
        "\n",
        "nearest_verses = get_nearest_verses_by_vector(df, search_index, embeddings_3, debug=True)"
      ],
      "metadata": {
        "id": "hTqo3Nv5hjAO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
